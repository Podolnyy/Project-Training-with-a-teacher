{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отток клиентов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.\n",
    "\n",
    "Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Вам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком. \n",
    "\n",
    "Постройте модель с предельно большим значением F1-меры. Чтобы сдать проект успешно, нужно довести метрику до 0.59. Проверьте F1-меру на тестовой выборке самостоятельно.\n",
    "\n",
    "Дополнительно измеряйте AUC-ROC, сравнивайте её значение с F1-мерой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подключим необходимые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    roc_auc_score, \n",
    "    f1_score, \n",
    "    recall_score\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Откройте и изучите файл"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Откроем файл и посмотрим на первые строки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv('')\n",
    "except:\n",
    "    df = pd.read_csv('')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Признаки:</u>\n",
    "- <b>RowNumber</b> — индекс строки в данных\n",
    "- <b>CustomerId</b> — уникальный идентификатор клиента\n",
    "- <b>Surname</b> — фамилия\n",
    "- <b>CreditScore</b> — кредитный рейтинг\n",
    "- <b>Geography</b> — страна проживания\n",
    "- <b>Gender</b> — пол\n",
    "- <b>Age</b> — возраст\n",
    "- <b>Tenure</b> — сколько лет человек является клиентом банка\n",
    "- <b>Balance</b> — баланс на счёте\n",
    "- <b>NumOfProducts</b> — количество продуктов банка, используемых клиентом\n",
    "- <b>HasCrCard</b> — наличие кредитной карты\n",
    "- <b>IsActiveMember</b> — активность клиента\n",
    "- <b>EstimatedSalary</b> — предполагаемая зарплата\n",
    "\n",
    "<u>Целевой признак:</u>\n",
    "- <b>Exited</b> — факт ухода клиента"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посмотрим наличие пропусков и обработаем их"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber            0\n",
       "CustomerId           0\n",
       "Surname              0\n",
       "CreditScore          0\n",
       "Geography            0\n",
       "Gender               0\n",
       "Age                  0\n",
       "Tenure             909\n",
       "Balance              0\n",
       "NumOfProducts        0\n",
       "HasCrCard            0\n",
       "IsActiveMember       0\n",
       "EstimatedSalary      0\n",
       "Exited               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum() #найдем тустые ячейки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Tenure'] = df['Tenure'].fillna(df['Tenure'].median()) \n",
    "df = df.dropna(subset=['Tenure']) \n",
    "#заполним пустые ячейки медианным значением"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber          0\n",
       "CustomerId         0\n",
       "Surname            0\n",
       "CreditScore        0\n",
       "Geography          0\n",
       "Gender             0\n",
       "Age                0\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "HasCrCard          0\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "Exited             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посмотрим наличие дубликатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку перед моделью стоит задача классификации (ушел клиент или нет), то для нас не имеют значения данные из колонок <b>RowNumber, CustomerId, Surname</b> - удалим их."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Удалим ненужные колонки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посмотрим снова на данные после обрабоки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42     2.0       0.00              1   \n",
       "1          608     Spain  Female   41     1.0   83807.86              1   \n",
       "2          502    France  Female   42     8.0  159660.80              3   \n",
       "3          699    France  Female   39     1.0       0.00              2   \n",
       "4          850     Spain  Female   43     2.0  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разбейте данные на выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество строк в валидационной выборке: 1819 , что составляет 0.2000879991200088\n",
      "Количество строк в тестовой выборке: 1818 , что составляет 0.1999780002199978\n",
      "Количество строк в тренировочной выборке: 5454 , что составляет 0.5999340006599934\n"
     ]
    }
   ],
   "source": [
    "features = df.drop(['Exited'], axis=1)\n",
    "target = df['Exited']\n",
    "\n",
    "features_nf, features_valid, target_nf, target_valid = train_test_split( \n",
    "    features, target, test_size=0.2, random_state=13)#в принципе, я думаю, можно было перезаписать признаки и цели\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features_nf, target_nf, test_size=0.25, random_state=13)\n",
    "\n",
    "print('Количество строк в валидационной выборке:', target_valid.count(),\n",
    "      ', что составляет', target_valid.count()/target.count())\n",
    "print('Количество строк в тестовой выборке:', target_test.count(),\n",
    "      ', что составляет', target_test.count()/target.count())\n",
    "print('Количество строк в тренировочной выборке:', target_train.count(),\n",
    "      ', что составляет', target_train.count()/target.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = pd.get_dummies(features_train, drop_first=True)\n",
    "features_valid = pd.get_dummies(features_valid, drop_first=True)\n",
    "features_test = pd.get_dummies(features_test, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исследуйте модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "#отключим тонну красного текста сообщающего неихвестно о чем..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = ['CreditScore', 'Age', 'Tenure', 'Balance', 'EstimatedSalary']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train[numeric])\n",
    "\n",
    "features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "features_valid[numeric] = scaler.transform(features_valid[numeric])\n",
    "features_test[numeric] = scaler.transform(features_test[numeric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посмотрим на поведедение различных моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Посмотрим модель решающего дерева\n",
    "best_model = None\n",
    "best_result = 0\n",
    "train_list = []\n",
    "valid_list = []\n",
    "for depth in range(1, 20):\n",
    "    model = DecisionTreeClassifier(random_state=12345,\n",
    "                                   max_depth=depth) #модель с заданной глубиной дерева\n",
    "    model.fit(features_train, target_train) # обучение модели\n",
    "    predictions = model.predict(features_valid) #предсказания модели\n",
    "    result = f1_score(target_valid, predictions) \n",
    "    acc = accuracy_score(target_valid, predictions)\n",
    "    valid_list.append(result)\n",
    "    if result > best_result:\n",
    "        best_model = model\n",
    "        best_result = result\n",
    "        best_depth = depth\n",
    "        best_acc = acc\n",
    "        probabilities_valid = best_model.predict_proba(features_valid)\n",
    "        probabilities_one_valid = probabilities_valid[:, 1]\n",
    "        auc_roc = roc_auc_score(target_valid, probabilities_one_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшая глубина:  7\n",
      "Accuracy лучшей модели: 0.8614623419461243\n",
      "F1 для Дерева решений: 0.5594405594405595\n",
      "AUC-ROC для Дерева решени: 0.8328027147694245\n"
     ]
    }
   ],
   "source": [
    "print(\"Наилучшая глубина: \", best_depth)\n",
    "print(\"Accuracy лучшей модели:\", best_acc)\n",
    "print(\"F1 для Дерева решений:\", best_result)\n",
    "print(\"AUC-ROC для Дерева решени:\", auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Целевая F1 должна быть равна 0.59, наша 0.56. Значит проверим другую модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Модель логистической регрессии\n",
    "model_log = LogisticRegression(random_state=12345, \n",
    "                               solver='liblinear', \n",
    "                               max_iter=100)\n",
    "model_log.fit(features_train, target_train)\n",
    "predictions_log = model_log.predict(features_valid)\n",
    "\n",
    "acc =  accuracy_score(target_valid, predictions_log)\n",
    "result = f1_score(target_valid, predictions) \n",
    "\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy лучшей модели: 0.8141836173721825\n",
      "F1 для Логистической регрессии: 0.4822888283378747\n",
      "AUC-ROC для Логистической регрессии: 0.6752914032301561\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy лучшей модели:\", acc)\n",
    "print(\"F1 для Логистической регрессии:\", result)\n",
    "print(\"AUC-ROC для Логистической регрессии:\", auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ожидаемо, метрики логистической регрессии еще ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Модель случайного леса\n",
    "best_model = None\n",
    "best_result = 0\n",
    "best_depth = 0\n",
    "for est in range(10, 101, 10):\n",
    "    for depth in range(1, 21, 1):\n",
    "        model = RandomForestClassifier(random_state=12345, \n",
    "                                              n_estimators=est,\n",
    "                                              max_depth=depth)\n",
    "        model.fit(features_train, target_train)\n",
    "        predictions_valid = model.predict(features_valid)\n",
    "        result = f1_score(target_valid, predictions_valid)\n",
    "        acc = accuracy_score(target_valid, predictions)\n",
    "        if result > best_result:\n",
    "            best_model = model\n",
    "            best_est = est\n",
    "            best_result = result\n",
    "            best_depth = depth\n",
    "            acc_best = acc\n",
    "            probabilities_valid = best_model.predict_proba(features_valid)\n",
    "            probabilities_one_valid = probabilities_valid[:, 1]\n",
    "            auc_roc = roc_auc_score(target_valid, probabilities_one_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Глубина 20\n",
      "Кол-во деревьев 100\n",
      "Accuracy для случайного леса 0.7910940076965366\n",
      "F1 для случайного леса 0.614065180102916\n",
      "AUC-ROC для Леса: 0.8563237871932401\n"
     ]
    }
   ],
   "source": [
    "print('Глубина',best_depth)\n",
    "print('Кол-во деревьев', best_est)\n",
    "print(\"Accuracy для случайного леса\", acc_best)\n",
    "print(\"F1 для случайного леса\", best_result)\n",
    "print(\"AUC-ROC для Леса:\", auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Странно, но факт: Модель решающего дерева имеет более высокие значение метрики F1, нежели случайный лес.\n",
    "\n",
    "Наилучшей с точки зрения метрики F1 оказалась модель _решающего дерева_ с показателем 0.581. Также у данной модели самая высокая точность 0.8595.\n",
    "\n",
    "Наилучшей с точки зрения AUC-ROC является модель _случайного леса_ с показателем 0.848.\n",
    "\n",
    "Поскольку мы так и не получили целевое значение F1, то будем работать с дисбалансом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дисбаланс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4359, 11)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1095, 11)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(features_train[target_train == 0].shape)\n",
    "features_train[target_train == 1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что один класс преобладает, количество данных различается в 4 раза."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1101, 11)\n",
      "(1095, 11)\n"
     ]
    }
   ],
   "source": [
    "def downsample(features, target, fraction):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "    \n",
    "    features_downsampled = pd.concat(\n",
    "        [features_zeros.sample(frac=fraction, random_state=12345)] + [features_ones])\n",
    "    target_downsampled = pd.concat(\n",
    "        [target_zeros.sample(frac=fraction, random_state=12345)] + [target_ones])\n",
    "    \n",
    "    features_downsampled, target_downsampled = shuffle(features_downsampled, \n",
    "                                                       target_downsampled, \n",
    "                                                       random_state=12345)\n",
    "    \n",
    "    return features_downsampled, target_downsampled\n",
    "\n",
    "features_downsampled, target_downsampled = downsample(features_train, \n",
    "                                                      target_train, \n",
    "                                                      1210/4790)\n",
    "\n",
    "print (features_downsampled[target_downsampled == 0].shape)\n",
    "print (features_downsampled[target_downsampled == 1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сбалансировали классы. Теперь рассмотрим модель решающего дерева, она была лучшей по метрике F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Посмотрим модель решающего дерева\n",
    "best_model = None\n",
    "best_result = 0\n",
    "train_list = []\n",
    "valid_list = []\n",
    "\n",
    "for depth in range(1, 20):\n",
    "    model = DecisionTreeClassifier(random_state=12345, \n",
    "                                   max_depth=depth) #модель с заданной глубиной дерева\n",
    "    model.fit(features_downsampled, target_downsampled) # обучение модели\n",
    "    predictions = model.predict(features_valid) #предсказания модели\n",
    "    result = f1_score(target_valid, predictions) \n",
    "    acc = accuracy_score(target_valid, predictions)\n",
    "    valid_list.append(result)\n",
    "    if result > best_result:\n",
    "        best_model = model\n",
    "        best_result = result\n",
    "        best_depth = depth\n",
    "        best_acc = acc\n",
    "        probabilities_valid = best_model.predict_proba(features_valid)\n",
    "        probabilities_one_valid = probabilities_valid[:, 1]\n",
    "        auc_roc = roc_auc_score(target_valid, probabilities_one_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшая глубина:  7\n",
      "Accuracy лучшей модели: 0.7762506871907642\n",
      "F1 для Дерева решений: 0.5782383419689119\n",
      "AUC-ROC для Дерева решени: 0.8200453959787852\n"
     ]
    }
   ],
   "source": [
    "print(\"Наилучшая глубина: \", best_depth)\n",
    "print(\"Accuracy лучшей модели:\", best_acc)\n",
    "print(\"F1 для Дерева решений:\", best_result)\n",
    "print(\"AUC-ROC для Дерева решени:\", auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Показатели метрик модели упали, что можно связать с уменьшением кол-ва данных для обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Модель логистической регрессии\n",
    "model_log = LogisticRegression(random_state=12345, \n",
    "                               solver='liblinear', \n",
    "                               max_iter=100)\n",
    "model_log.fit(features_downsampled, target_downsampled)\n",
    "predictions_log = model_log.predict(features_valid)\n",
    "\n",
    "acc =  accuracy_score(target_valid, predictions_log)\n",
    "result = f1_score(target_valid, predictions_log)\n",
    "\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy лучшей модели: 0.7328202308960967\n",
      "F1 для Логистической регрессии: 0.5225933202357563\n",
      "AUC-ROC для Логистической регрессии: 0.6991327195637191\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy лучшей модели:\", acc)\n",
    "print(\"F1 для Логистической регрессии:\", result)\n",
    "print(\"AUC-ROC для Логистической регрессии:\", auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В модели логистической регрессии матрика F1 значительно возросла и превышает целевой показатель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Модель случайного леса\n",
    "best_model = None\n",
    "best_result = 0\n",
    "best_depth = 0\n",
    "for est in range(10, 101, 10):\n",
    "    for depth in range(1, 21, 1):\n",
    "        model = RandomForestClassifier(random_state=12345, \n",
    "                                              n_estimators=est,\n",
    "                                              max_depth=depth)\n",
    "        model.fit(features_downsampled, target_downsampled)\n",
    "        predictions_valid = model.predict(features_valid)\n",
    "        result = f1_score(target_valid, predictions_valid)\n",
    "        acc = accuracy_score(target_valid, predictions)\n",
    "        if result > best_result:\n",
    "            best_model = model\n",
    "            best_est = est\n",
    "            best_result = result\n",
    "            best_depth = depth\n",
    "            acc_best = acc\n",
    "            probabilities_valid = best_model.predict_proba(features_valid)\n",
    "            probabilities_one_valid = probabilities_valid[:, 1]\n",
    "            auc_roc = roc_auc_score(target_valid, probabilities_one_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Глубина 8\n",
      "Кол-во деревьев 100\n",
      "Accuracy для случайного леса 0.6943375481033535\n",
      "F1 для случайного леса 0.6205357142857143\n",
      "AUC-ROC для Леса: 0.8663852515506548\n"
     ]
    }
   ],
   "source": [
    "print('Глубина',best_depth)\n",
    "print('Кол-во деревьев', best_est)\n",
    "print(\"Accuracy для случайного леса\", acc_best)\n",
    "print(\"F1 для случайного леса\", best_result)\n",
    "print(\"AUC-ROC для Леса:\", auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целом, после такого балансирования качество моделей не ухудшилось, но и сказать, что оно стало лучше - тоже нельзя."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(features, target, repeat): \n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "    \n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat) \n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    features_upsampled, target_upsampled = shuffle( features_upsampled, target_upsampled, random_state=12345)\n",
    "    \n",
    "    return features_upsampled, target_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4359, 11)\n",
      "(4380, 11)\n"
     ]
    }
   ],
   "source": [
    "features_upsampled, target_upsampled = upsample(features_train,\n",
    "                                                target_train, \n",
    "                                                4)\n",
    "\n",
    "print (features_upsampled[target_upsampled == 0].shape)\n",
    "print (features_upsampled[target_upsampled == 1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Увеличили меньшую выборку до уровня бОльшей.\n",
    "\n",
    "Теперь повторим действия для моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Посмотрим модель решающего дерева\n",
    "best_model = None\n",
    "best_result = 0\n",
    "train_list = []\n",
    "valid_list = []\n",
    "\n",
    "for depth in range(1, 20):\n",
    "    model = DecisionTreeClassifier(random_state=12345, \n",
    "                                   max_depth=depth) #модель с заданной глубиной дерева\n",
    "    model.fit(features_upsampled, target_upsampled) # обучение модели\n",
    "    predictions = model.predict(features_valid) #предсказания модели\n",
    "    result = f1_score(target_valid, predictions) \n",
    "    acc = accuracy_score(target_valid, predictions)\n",
    "    valid_list.append(result)\n",
    "    if result > best_result:\n",
    "        best_model = model\n",
    "        best_result = result\n",
    "        best_depth = depth\n",
    "        best_acc = acc\n",
    "        probabilities_valid = best_model.predict_proba(features_valid)\n",
    "        probabilities_one_valid = probabilities_valid[:, 1]\n",
    "        auc_roc = roc_auc_score(target_valid, probabilities_one_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшая глубина:  5\n",
      "Accuracy лучшей модели: 0.7713029136888401\n",
      "F1 для Дерева решений: 0.574642126789366\n",
      "AUC-ROC для Дерева решени: 0.8385951967159081\n"
     ]
    }
   ],
   "source": [
    "print(\"Наилучшая глубина: \", best_depth)\n",
    "print(\"Accuracy лучшей модели:\", best_acc)\n",
    "print(\"F1 для Дерева решений:\", best_result)\n",
    "print(\"AUC-ROC для Дерева решени:\", auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Странно, но факт - метрики упали по сравнению с несбалансированной выборкой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Модель логистической регрессии\n",
    "model_log = LogisticRegression(random_state=12345, \n",
    "                               solver='liblinear', \n",
    "                               max_iter=100)\n",
    "model_log.fit(features_upsampled, target_upsampled)\n",
    "predictions_log = model_log.predict(features_valid)\n",
    "\n",
    "acc =  accuracy_score(target_valid, predictions_log)\n",
    "result = f1_score(target_valid, predictions_log)\n",
    "\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy лучшей модели: 0.719626168224299\n",
      "F1 для Логистической регрессии: 0.4990176817288801\n",
      "AUC-ROC для Логистической регрессии: 0.6978639169388428\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy лучшей модели:\", acc)\n",
    "print(\"F1 для Логистической регрессии:\", result)\n",
    "print(\"AUC-ROC для Логистической регрессии:\", auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так же как и в случае даунсемплинга показатели выросли по отношению модели, обученной на исходных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Модель случайного леса\n",
    "best_model = None\n",
    "best_result = 0\n",
    "best_depth = 0\n",
    "for est in range(10, 101, 10):\n",
    "    for depth in range(1, 21, 1):\n",
    "        model = RandomForestClassifier(random_state=12345, \n",
    "                                              n_estimators=est,\n",
    "                                              max_depth=depth)\n",
    "        model.fit(features_upsampled, target_upsampled)\n",
    "        predictions_valid = model.predict(features_valid)\n",
    "        result = f1_score(target_valid, predictions_valid)\n",
    "        acc = accuracy_score(target_valid, predictions)\n",
    "        if result > best_result:\n",
    "            best_model = model\n",
    "            best_est = est\n",
    "            best_result = result\n",
    "            best_depth = depth\n",
    "            acc_best = acc\n",
    "            probabilities_valid = best_model.predict_proba(features_valid)\n",
    "            probabilities_one_valid = probabilities_valid[:, 1]\n",
    "            auc_roc = roc_auc_score(target_valid, probabilities_one_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Глубина 12\n",
      "Кол-во деревьев 60\n",
      "Accuracy для случайного леса 0.8037383177570093\n",
      "F1 для случайного леса 0.6370967741935484\n",
      "AUC-ROC для Леса: 0.8630929194258831\n"
     ]
    }
   ],
   "source": [
    "print('Глубина',best_depth)\n",
    "print('Кол-во деревьев', best_est)\n",
    "print(\"Accuracy для случайного леса\", acc_best)\n",
    "print(\"F1 для случайного леса\", best_result)\n",
    "print(\"AUC-ROC для Леса:\", auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подводя итог после работы с дисбалансом можно сказать, что наибольший показатель метрики F1 имеет модель Случайного леса. Так же нашли оптимальные гиперпараметры для нашего случая."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку наиболее высокий результат показала модель Случайного леса, то будем рассматривать ее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Модель случайного леса\n",
    "model = RandomForestClassifier(random_state=12345, \n",
    "                               n_estimators=100,\n",
    "                               max_depth=12, \n",
    "                               class_weight='balanced')\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "predict = model.predict(features_test)\n",
    "result = f1_score(target_test, predict)\n",
    "acc = accuracy_score(target_test, predict)\n",
    "\n",
    "probabilities_test = model.predict_proba(features_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "auc_roc = roc_auc_score(target_test, probabilities_one_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8536853685368537\n",
      "F1 для Логистической регрессии: 0.6253521126760563\n",
      "AUC-ROC для Логистической регрессии: 0.8636651211473285\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", acc)\n",
    "print(\"F1 для Логистической регрессии:\", result)\n",
    "print(\"AUC-ROC для Логистической регрессии:\", auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Была произведена предобработка данных, удалены пропуски. Использована ОНЕ.\n",
    "\n",
    "Далее данные были разбиты на 3 выборки - тренировочную, валидационную и тестовую.\n",
    "\n",
    "Исследован баланс классов. Произведено обучение 3 моделей и исследованы их метрики без учете дисбаланса. В ходе обучения было принято решение, что наиболее точной является модель _случайного леса_. \n",
    "\n",
    "Преобразованы данные для обучения (downsampling, upsampling). Был учтен дисбаланс в обучении моделей, модели были переобучены. Качество моделей после переобучения возросло.\n",
    "\n",
    "На тестовой выборке модель _случайного леса_ показала следующие <u>?качественные?</u> метрики:\n",
    "\n",
    "- Accuracy: 0.8536853685368537\n",
    "- F1 для Логистической регрессии: 0.6253521126760563\n",
    "- AUC-ROC для Логистической регрессии: 0.8636651211473285\n",
    "\n",
    "Таким образом мы добились уровня F1 0.625, что выше целевого показателя (0.59)."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1533,
    "start_time": "2023-03-10T16:18:02.172Z"
   },
   {
    "duration": 147,
    "start_time": "2023-03-10T16:18:03.707Z"
   },
   {
    "duration": 35,
    "start_time": "2023-03-10T16:18:03.856Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-10T16:18:03.898Z"
   },
   {
    "duration": 12,
    "start_time": "2023-03-10T16:18:03.914Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-10T16:18:03.928Z"
   },
   {
    "duration": 14,
    "start_time": "2023-03-10T16:18:03.939Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-10T16:18:03.954Z"
   },
   {
    "duration": 23,
    "start_time": "2023-03-10T16:18:03.965Z"
   },
   {
    "duration": 24,
    "start_time": "2023-03-10T16:18:03.990Z"
   },
   {
    "duration": 22,
    "start_time": "2023-03-10T16:18:04.015Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-10T16:18:04.039Z"
   },
   {
    "duration": 45,
    "start_time": "2023-03-10T16:18:04.044Z"
   },
   {
    "duration": 520,
    "start_time": "2023-03-10T16:18:04.097Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-10T16:18:04.619Z"
   },
   {
    "duration": 54,
    "start_time": "2023-03-10T16:18:04.627Z"
   },
   {
    "duration": 111,
    "start_time": "2023-03-10T16:18:04.693Z"
   },
   {
    "duration": 67744,
    "start_time": "2023-03-10T16:18:04.805Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-10T16:19:12.550Z"
   },
   {
    "duration": 31,
    "start_time": "2023-03-10T16:19:12.557Z"
   },
   {
    "duration": 31,
    "start_time": "2023-03-10T16:19:12.590Z"
   },
   {
    "duration": 283,
    "start_time": "2023-03-10T16:19:12.623Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-10T16:19:12.909Z"
   },
   {
    "duration": 65,
    "start_time": "2023-03-10T16:19:12.916Z"
   },
   {
    "duration": 89,
    "start_time": "2023-03-10T16:19:12.989Z"
   },
   {
    "duration": 39375,
    "start_time": "2023-03-10T16:19:13.080Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-10T16:19:52.456Z"
   },
   {
    "duration": 45,
    "start_time": "2023-03-10T16:19:52.464Z"
   },
   {
    "duration": 45,
    "start_time": "2023-03-10T16:19:52.511Z"
   },
   {
    "duration": 655,
    "start_time": "2023-03-10T16:19:52.558Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-10T16:19:53.215Z"
   },
   {
    "duration": 155,
    "start_time": "2023-03-10T16:19:53.222Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-10T16:19:53.380Z"
   },
   {
    "duration": 92322,
    "start_time": "2023-03-10T16:19:53.387Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-10T16:21:25.712Z"
   },
   {
    "duration": 765,
    "start_time": "2023-03-10T16:21:25.720Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-10T16:21:26.487Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
